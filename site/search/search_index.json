{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dados do M\u00f3dulo Agosto \u00b6 Data Sourcing e Data Analysis com R Studio Arquitetura e Governan\u00e7a de Dados na Nuvem 1 Arquitetura e Governan\u00e7a de Dados na Nuvem 2 Ingest\u00e3o e Processamento de Dados (Framework de testes e qualidade) Seguran\u00e7a e Governan\u00e7a de Dados (LGPD) Precifica\u00e7\u00e3o em Nuvem Setembro \u00b6 M\u00e9tricas, Telemetria e Gest\u00e3o de Microservi\u00e7os Data Lakes e Data Warehouses Servi\u00e7os e ETLs para Transforma\u00e7\u00e3o de Dados e Processamento de Dados em Escala Processamento de Dados na Nuvem Ciclo de Vida e Automatiza\u00e7\u00e3o de Pipeline de Dados (MLOps) Processamento e Predi\u00e7\u00e3o em Produ\u00e7\u00e3o Outubro \u00b6 User Interface e Dashboards Data Storytelling Boas Pr\u00e1ticas para o M\u00f3dulo \u00b6 Iremos utilizar fortemente o GitFlow Sugiro que voc\u00eas utilizem o GitGraph para VSCode Sugiro que o VSCode seja nosso ambiente principal de codifica\u00e7\u00e3o Instale o Pyhton 3.12 e sete como global Instale o code tools na op\u00e7\u00e3o de instala\u00e7\u00e3o se for por windows Vamos utilizar muito o Powershell no windows, se acostume! Desinstale o Github Desktop! \u00c9 s\u00e9rio... Tenha instalado o Docker e o Docker Compose Instale o R em sua \u00faltima vers\u00e3o e o RStudio Padronize seu nickname do git no seu computador desta forma: git config --global user.name \"Seu Nome\" git config --global user.email \"seu_email@exemplo.com\" Mantendo o mesmo username e email em todo o m\u00f3dulo! ou instale o gh ou github cli M\u00f3dulo 11 de Engenharia de Software: An\u00e1lise de Dados com RStudio \u00b6 Introdu\u00e7\u00e3o \u00b6 Nesta aula, vamos explorar a an\u00e1lise de dados avan\u00e7ada utilizando o RStudio e diversas ferramentas de suporte. Nosso parceiro, o Boston Consulting Group (BCG), fornecer\u00e1 arquivos CSV de grande porte para an\u00e1lise. Vamos abordar desde a padroniza\u00e7\u00e3o e normaliza\u00e7\u00e3o dos dados at\u00e9 a constru\u00e7\u00e3o de uma aplica\u00e7\u00e3o de an\u00e1lise de dados utilizando diversas tecnologias. Utilizaremos o conceito de processamento de dados \"Raw\", \"Working\" e \"Trusted\". Arquitetura e Ferramentas \u00b6 Ferramentas Utilizadas \u00b6 RStudio \u00b6 Descri\u00e7\u00e3o : Ambiente de desenvolvimento integrado (IDE) para a linguagem de programa\u00e7\u00e3o R. Uso : An\u00e1lise de dados, gera\u00e7\u00e3o de relat\u00f3rios e visualiza\u00e7\u00f5es. Mais detalhes : RStudio \u00e9 uma IDE poderosa para R que facilita a an\u00e1lise de dados, a cria\u00e7\u00e3o de gr\u00e1ficos e a gera\u00e7\u00e3o de relat\u00f3rios. Ele oferece uma interface amig\u00e1vel e ferramentas integradas para ajudar na codifica\u00e7\u00e3o, depura\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados. RMarkdown \u00b6 Descri\u00e7\u00e3o : Ferramenta para criar documentos din\u00e2micos com R. Uso : Gera\u00e7\u00e3o de relat\u00f3rios para cada arquivo CSV analisado. Mais detalhes : RMarkdown permite a cria\u00e7\u00e3o de documentos din\u00e2micos que combinam c\u00f3digo R, texto e visualiza\u00e7\u00f5es. \u00c9 ideal para gerar relat\u00f3rios que podem ser facilmente atualizados com novos dados. Appwrite \u00b6 Descri\u00e7\u00e3o : Plataforma de Backend as a Service (BaaS) que oferece servi\u00e7os como autentica\u00e7\u00e3o, banco de dados, armazenamento e muito mais. Uso : Armazenamento de dados raw e dados processados, utilizando o storage e MariaDB. Mais detalhes : Appwrite \u00e9 uma plataforma BaaS que simplifica o desenvolvimento de aplicativos ao fornecer servi\u00e7os essenciais como autentica\u00e7\u00e3o, banco de dados, armazenamento de arquivos e muito mais, tudo em uma \u00fanica solu\u00e7\u00e3o. MariaDB \u00b6 Descri\u00e7\u00e3o : Sistema de gerenciamento de banco de dados relacional. Uso : Armazenamento de dados processados (dados working). Mais detalhes : MariaDB \u00e9 um sistema de gerenciamento de banco de dados relacional que \u00e9 uma bifurca\u00e7\u00e3o do MySQL. Ele \u00e9 conhecido por sua escalabilidade, desempenho e robustez, sendo amplamente utilizado para armazenar dados estruturados. ElasticSearch \u00b6 Descri\u00e7\u00e3o : Motor de busca e an\u00e1lise distribu\u00eddo e de c\u00f3digo aberto. Uso : Indexa\u00e7\u00e3o e busca avan\u00e7ada dos dados processados. Mais detalhes : ElasticSearch \u00e9 uma ferramenta poderosa para busca e an\u00e1lise de dados em tempo real. Ele permite a indexa\u00e7\u00e3o r\u00e1pida e eficiente de grandes volumes de dados, facilitando a busca e a an\u00e1lise avan\u00e7ada. ClickHouse \u00b6 Descri\u00e7\u00e3o : Sistema de gerenciamento de banco de dados orientado a colunas, de c\u00f3digo aberto, para consultas anal\u00edticas em tempo real. Uso : Armazenamento e an\u00e1lise de dados processados (dados trusted). Mais detalhes : ClickHouse \u00e9 um sistema de banco de dados orientado a colunas que \u00e9 otimizado para consultas anal\u00edticas em tempo real. Ele \u00e9 ideal para grandes volumes de dados e oferece desempenho excepcional para an\u00e1lises complexas. Streamlit \u00b6 Descri\u00e7\u00e3o : Framework de c\u00f3digo aberto para a cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas em Python. Uso : Constru\u00e7\u00e3o de uma aplica\u00e7\u00e3o de an\u00e1lise de dados (DataApp). Mais detalhes : Streamlit \u00e9 um framework que facilita a cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas para an\u00e1lise de dados. Com ele, \u00e9 poss\u00edvel transformar scripts Python em aplicativos web de forma r\u00e1pida e eficiente. Apache Spark \u00b6 Descri\u00e7\u00e3o : Motor de an\u00e1lise unificada para processamento de dados em grande escala. Uso : Processamento e predi\u00e7\u00e3o de dados em produ\u00e7\u00e3o. Mais detalhes : Apache Spark \u00e9 uma plataforma de processamento de dados em grande escala que oferece suporte para processamento em lote e em tempo real. Ele \u00e9 amplamente utilizado para an\u00e1lise de big data e aprendizado de m\u00e1quina. Docker \u00b6 Descri\u00e7\u00e3o : Plataforma para desenvolvimento, envio e execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres. Uso : Dockeriza\u00e7\u00e3o da aplica\u00e7\u00e3o Streamlit, ElasticSearch e ClickHouse. Mais detalhes : Docker \u00e9 uma plataforma que permite a cria\u00e7\u00e3o, envio e execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres. Ele facilita a portabilidade e a escalabilidade das aplica\u00e7\u00f5es, garantindo que elas funcionem de maneira consistente em diferentes ambientes. Poetry \u00b6 Descri\u00e7\u00e3o : Gestor de pacotes e depend\u00eancias para projetos Python. Uso : Gerenciamento de depend\u00eancias da aplica\u00e7\u00e3o Streamlit. Mais detalhes : Poetry \u00e9 uma ferramenta para gerenciamento de depend\u00eancias e pacotes em projetos Python. Ele simplifica a instala\u00e7\u00e3o e atualiza\u00e7\u00e3o de bibliotecas, garantindo que todas as depend\u00eancias sejam resolvidas corretamente. Portainer \u00b6 Descri\u00e7\u00e3o : Interface de gerenciamento para Docker. Uso : Gerenciamento de cont\u00eaineres Docker. Mais detalhes : Portainer \u00e9 uma interface de usu\u00e1rio para gerenciamento de cont\u00eaineres Docker. Ele facilita a administra\u00e7\u00e3o de ambientes Docker, permitindo a visualiza\u00e7\u00e3o, cria\u00e7\u00e3o e gerenciamento de cont\u00eaineres de forma intuitiva. Descri\u00e7\u00e3o : Interface de gerenciamento para Docker. Uso : Gerenciamento de cont\u00eaineres Docker. Mais detalhes Portainer \u00e9 uma interface de usu\u00e1rio para gerenciamento de cont\u00eaineres Docker. Ele facilita a administra\u00e7\u00e3o de ambientes Docker, permitindo a visualiza\u00e7\u00e3o, cria\u00e7\u00e3o e gerenciamento de cont\u00eaineres de forma intuitiva. Arquitetura de Processamento de Dados \u00b6 Recebimento dos Arquivos CSV - Os arquivos CSV fornecidos pelo BCG ser\u00e3o carregados no RStudio para an\u00e1lise inicial. An\u00e1lise e Padroniza\u00e7\u00e3o dos Dados - Utilizando RStudio, os dados ser\u00e3o ajustados e padronizados. - Relat\u00f3rios ser\u00e3o gerados em RMarkdown para cada arquivo CSV. Armazenamento dos Dados Raw - Os arquivos CSV originais ser\u00e3o armazenados no storage do Appwrite. Normaliza\u00e7\u00e3o e Processamento dos Dados - Os dados ser\u00e3o normalizados e processados no RStudio. - Dados processados (dados working) ser\u00e3o armazenados no MariaDB do Appwrite. Indexa\u00e7\u00e3o e Armazenamento de Dados Trusted - Um cont\u00eainer Docker do ElasticSearch ser\u00e1 configurado para indexa\u00e7\u00e3o e busca avan\u00e7ada. - Alternativamente, um cont\u00eainer Docker do ClickHouse ser\u00e1 configurado para armazenamento e an\u00e1lise de dados processados. - Dados do MariaDB ser\u00e3o indexados no ElasticSearch ou armazenados no ClickHouse. Constru\u00e7\u00e3o da Aplica\u00e7\u00e3o DataApp - Utilizando Streamlit, uma aplica\u00e7\u00e3o interativa ser\u00e1 desenvolvida para consumir dados do MariaDB, ElasticSearch e ClickHouse. - A aplica\u00e7\u00e3o ser\u00e1 dockerizada e gerenciada com Poetry. Processamento com Apache Spark - Apache Spark ser\u00e1 utilizado para realizar predi\u00e7\u00f5es com os dados em produ\u00e7\u00e3o. O que \u00e9 Backend as a Service (BaaS)? \u00b6 Backend as a Service (BaaS) \u00e9 um modelo de servi\u00e7o que fornece uma infraestrutura de backend pronta para uso, permitindo que desenvolvedores se concentrem no desenvolvimento do frontend e na l\u00f3gica de neg\u00f3cios. O BaaS oferece servi\u00e7os como autentica\u00e7\u00e3o, banco de dados, armazenamento de arquivos, notifica\u00e7\u00f5es push, entre outros, eliminando a necessidade de gerenciar servidores e infraestrutura. ElasticSearch vs ClickHouse \u00b6 ElasticSearch \u00b6 Descri\u00e7\u00e3o : Motor de busca e an\u00e1lise distribu\u00eddo, ideal para indexa\u00e7\u00e3o e busca avan\u00e7ada. Vantagens : - Excelente para buscas textuais e an\u00e1lises em tempo real. - Suporte robusto para consultas complexas e agrega\u00e7\u00f5es. Desvantagens : - Pode ser mais complexo de configurar e gerenciar para grandes volumes de dados. ClickHouse \u00b6 Descri\u00e7\u00e3o : Sistema de gerenciamento de banco de dados orientado a colunas, otimizado para consultas anal\u00edticas em tempo real. Vantagens : - Desempenho extremamente r\u00e1pido para consultas anal\u00edticas. - Otimizado para grandes volumes de dados e consultas de leitura intensiva. Desvantagens : - Menos adequado para buscas textuais complexas comparado ao ElasticSearch. Toda a arquitetura ser\u00e1 criada com Docker e rodar\u00e1 on-premise, mas poder\u00e1 ser facilmente integrada em uma nuvem ajustando os ambientes de conex\u00e3o (envs). Ferramentas e Tecnologias \u00b6 Ferramenta Descri\u00e7\u00e3o Uso RStudio IDE para R An\u00e1lise de dados, gera\u00e7\u00e3o de relat\u00f3rios RMarkdown Ferramenta para documentos din\u00e2micos Gera\u00e7\u00e3o de relat\u00f3rios Appwrite Plataforma de BaaS Armazenamento de dados raw e processados MariaDB Sistema de gerenciamento de banco de dados relacional Armazenamento de dados processados ElasticSearch Motor de busca e an\u00e1lise distribu\u00eddo Indexa\u00e7\u00e3o e busca avan\u00e7ada dos dados ClickHouse Sistema de gerenciamento de banco de dados orientado a colunas Armazenamento e an\u00e1lise de dados processados Streamlit Framework para cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas Constru\u00e7\u00e3o de uma aplica\u00e7\u00e3o de an\u00e1lise de dados (DataApp) Apache Spark Motor de an\u00e1lise unificada para processamento de dados em grande escala Processamento e predi\u00e7\u00e3o de dados Docker Plataforma para desenvolvimento, envio e execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres Dockeriza\u00e7\u00e3o da aplica\u00e7\u00e3o Streamlit, ElasticSearch e ClickHouse Poetry Gestor de pacotes e depend\u00eancias para projetos Python Gerenciamento de depend\u00eancias da aplica\u00e7\u00e3o Streamlit Mas isso n\u00e3o \u00e9 ferro e fogo! \u00b6 Sinta-se a vontade para trazer novas tecnologias para o nosso m\u00f3dulo! Conte com os professores para analisarmos juntos novas solu\u00e7\u00f5es. Aqui vai o refactoring Guru para dar novas ideias \u00e0 voc\u00eas =) Refactoring Guru","title":"Home"},{"location":"#agosto","text":"Data Sourcing e Data Analysis com R Studio Arquitetura e Governan\u00e7a de Dados na Nuvem 1 Arquitetura e Governan\u00e7a de Dados na Nuvem 2 Ingest\u00e3o e Processamento de Dados (Framework de testes e qualidade) Seguran\u00e7a e Governan\u00e7a de Dados (LGPD) Precifica\u00e7\u00e3o em Nuvem","title":"Agosto"},{"location":"#setembro","text":"M\u00e9tricas, Telemetria e Gest\u00e3o de Microservi\u00e7os Data Lakes e Data Warehouses Servi\u00e7os e ETLs para Transforma\u00e7\u00e3o de Dados e Processamento de Dados em Escala Processamento de Dados na Nuvem Ciclo de Vida e Automatiza\u00e7\u00e3o de Pipeline de Dados (MLOps) Processamento e Predi\u00e7\u00e3o em Produ\u00e7\u00e3o","title":"Setembro"},{"location":"#outubro","text":"User Interface e Dashboards Data Storytelling","title":"Outubro"},{"location":"#boas-praticas-para-o-modulo","text":"Iremos utilizar fortemente o GitFlow Sugiro que voc\u00eas utilizem o GitGraph para VSCode Sugiro que o VSCode seja nosso ambiente principal de codifica\u00e7\u00e3o Instale o Pyhton 3.12 e sete como global Instale o code tools na op\u00e7\u00e3o de instala\u00e7\u00e3o se for por windows Vamos utilizar muito o Powershell no windows, se acostume! Desinstale o Github Desktop! \u00c9 s\u00e9rio... Tenha instalado o Docker e o Docker Compose Instale o R em sua \u00faltima vers\u00e3o e o RStudio Padronize seu nickname do git no seu computador desta forma: git config --global user.name \"Seu Nome\" git config --global user.email \"seu_email@exemplo.com\" Mantendo o mesmo username e email em todo o m\u00f3dulo! ou instale o gh ou github cli","title":"Boas Pr\u00e1ticas para o M\u00f3dulo"},{"location":"#modulo-11-de-engenharia-de-software-analise-de-dados-com-rstudio","text":"","title":"M\u00f3dulo 11 de Engenharia de Software: An\u00e1lise de Dados com RStudio"},{"location":"#introducao","text":"Nesta aula, vamos explorar a an\u00e1lise de dados avan\u00e7ada utilizando o RStudio e diversas ferramentas de suporte. Nosso parceiro, o Boston Consulting Group (BCG), fornecer\u00e1 arquivos CSV de grande porte para an\u00e1lise. Vamos abordar desde a padroniza\u00e7\u00e3o e normaliza\u00e7\u00e3o dos dados at\u00e9 a constru\u00e7\u00e3o de uma aplica\u00e7\u00e3o de an\u00e1lise de dados utilizando diversas tecnologias. Utilizaremos o conceito de processamento de dados \"Raw\", \"Working\" e \"Trusted\".","title":"Introdu\u00e7\u00e3o"},{"location":"#arquitetura-e-ferramentas","text":"","title":"Arquitetura e Ferramentas"},{"location":"#ferramentas-utilizadas","text":"","title":"Ferramentas Utilizadas"},{"location":"#rstudio","text":"Descri\u00e7\u00e3o : Ambiente de desenvolvimento integrado (IDE) para a linguagem de programa\u00e7\u00e3o R. Uso : An\u00e1lise de dados, gera\u00e7\u00e3o de relat\u00f3rios e visualiza\u00e7\u00f5es. Mais detalhes : RStudio \u00e9 uma IDE poderosa para R que facilita a an\u00e1lise de dados, a cria\u00e7\u00e3o de gr\u00e1ficos e a gera\u00e7\u00e3o de relat\u00f3rios. Ele oferece uma interface amig\u00e1vel e ferramentas integradas para ajudar na codifica\u00e7\u00e3o, depura\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados.","title":"RStudio"},{"location":"#rmarkdown","text":"Descri\u00e7\u00e3o : Ferramenta para criar documentos din\u00e2micos com R. Uso : Gera\u00e7\u00e3o de relat\u00f3rios para cada arquivo CSV analisado. Mais detalhes : RMarkdown permite a cria\u00e7\u00e3o de documentos din\u00e2micos que combinam c\u00f3digo R, texto e visualiza\u00e7\u00f5es. \u00c9 ideal para gerar relat\u00f3rios que podem ser facilmente atualizados com novos dados.","title":"RMarkdown"},{"location":"#appwrite","text":"Descri\u00e7\u00e3o : Plataforma de Backend as a Service (BaaS) que oferece servi\u00e7os como autentica\u00e7\u00e3o, banco de dados, armazenamento e muito mais. Uso : Armazenamento de dados raw e dados processados, utilizando o storage e MariaDB. Mais detalhes : Appwrite \u00e9 uma plataforma BaaS que simplifica o desenvolvimento de aplicativos ao fornecer servi\u00e7os essenciais como autentica\u00e7\u00e3o, banco de dados, armazenamento de arquivos e muito mais, tudo em uma \u00fanica solu\u00e7\u00e3o.","title":"Appwrite"},{"location":"#mariadb","text":"Descri\u00e7\u00e3o : Sistema de gerenciamento de banco de dados relacional. Uso : Armazenamento de dados processados (dados working). Mais detalhes : MariaDB \u00e9 um sistema de gerenciamento de banco de dados relacional que \u00e9 uma bifurca\u00e7\u00e3o do MySQL. Ele \u00e9 conhecido por sua escalabilidade, desempenho e robustez, sendo amplamente utilizado para armazenar dados estruturados.","title":"MariaDB"},{"location":"#elasticsearch","text":"Descri\u00e7\u00e3o : Motor de busca e an\u00e1lise distribu\u00eddo e de c\u00f3digo aberto. Uso : Indexa\u00e7\u00e3o e busca avan\u00e7ada dos dados processados. Mais detalhes : ElasticSearch \u00e9 uma ferramenta poderosa para busca e an\u00e1lise de dados em tempo real. Ele permite a indexa\u00e7\u00e3o r\u00e1pida e eficiente de grandes volumes de dados, facilitando a busca e a an\u00e1lise avan\u00e7ada.","title":"ElasticSearch"},{"location":"#clickhouse","text":"Descri\u00e7\u00e3o : Sistema de gerenciamento de banco de dados orientado a colunas, de c\u00f3digo aberto, para consultas anal\u00edticas em tempo real. Uso : Armazenamento e an\u00e1lise de dados processados (dados trusted). Mais detalhes : ClickHouse \u00e9 um sistema de banco de dados orientado a colunas que \u00e9 otimizado para consultas anal\u00edticas em tempo real. Ele \u00e9 ideal para grandes volumes de dados e oferece desempenho excepcional para an\u00e1lises complexas.","title":"ClickHouse"},{"location":"#streamlit","text":"Descri\u00e7\u00e3o : Framework de c\u00f3digo aberto para a cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas em Python. Uso : Constru\u00e7\u00e3o de uma aplica\u00e7\u00e3o de an\u00e1lise de dados (DataApp). Mais detalhes : Streamlit \u00e9 um framework que facilita a cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas para an\u00e1lise de dados. Com ele, \u00e9 poss\u00edvel transformar scripts Python em aplicativos web de forma r\u00e1pida e eficiente.","title":"Streamlit"},{"location":"#apache-spark","text":"Descri\u00e7\u00e3o : Motor de an\u00e1lise unificada para processamento de dados em grande escala. Uso : Processamento e predi\u00e7\u00e3o de dados em produ\u00e7\u00e3o. Mais detalhes : Apache Spark \u00e9 uma plataforma de processamento de dados em grande escala que oferece suporte para processamento em lote e em tempo real. Ele \u00e9 amplamente utilizado para an\u00e1lise de big data e aprendizado de m\u00e1quina.","title":"Apache Spark"},{"location":"#docker","text":"Descri\u00e7\u00e3o : Plataforma para desenvolvimento, envio e execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres. Uso : Dockeriza\u00e7\u00e3o da aplica\u00e7\u00e3o Streamlit, ElasticSearch e ClickHouse. Mais detalhes : Docker \u00e9 uma plataforma que permite a cria\u00e7\u00e3o, envio e execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres. Ele facilita a portabilidade e a escalabilidade das aplica\u00e7\u00f5es, garantindo que elas funcionem de maneira consistente em diferentes ambientes.","title":"Docker"},{"location":"#poetry","text":"Descri\u00e7\u00e3o : Gestor de pacotes e depend\u00eancias para projetos Python. Uso : Gerenciamento de depend\u00eancias da aplica\u00e7\u00e3o Streamlit. Mais detalhes : Poetry \u00e9 uma ferramenta para gerenciamento de depend\u00eancias e pacotes em projetos Python. Ele simplifica a instala\u00e7\u00e3o e atualiza\u00e7\u00e3o de bibliotecas, garantindo que todas as depend\u00eancias sejam resolvidas corretamente.","title":"Poetry"},{"location":"#portainer","text":"Descri\u00e7\u00e3o : Interface de gerenciamento para Docker. Uso : Gerenciamento de cont\u00eaineres Docker. Mais detalhes : Portainer \u00e9 uma interface de usu\u00e1rio para gerenciamento de cont\u00eaineres Docker. Ele facilita a administra\u00e7\u00e3o de ambientes Docker, permitindo a visualiza\u00e7\u00e3o, cria\u00e7\u00e3o e gerenciamento de cont\u00eaineres de forma intuitiva. Descri\u00e7\u00e3o : Interface de gerenciamento para Docker. Uso : Gerenciamento de cont\u00eaineres Docker. Mais detalhes Portainer \u00e9 uma interface de usu\u00e1rio para gerenciamento de cont\u00eaineres Docker. Ele facilita a administra\u00e7\u00e3o de ambientes Docker, permitindo a visualiza\u00e7\u00e3o, cria\u00e7\u00e3o e gerenciamento de cont\u00eaineres de forma intuitiva.","title":"Portainer"},{"location":"#arquitetura-de-processamento-de-dados","text":"Recebimento dos Arquivos CSV - Os arquivos CSV fornecidos pelo BCG ser\u00e3o carregados no RStudio para an\u00e1lise inicial. An\u00e1lise e Padroniza\u00e7\u00e3o dos Dados - Utilizando RStudio, os dados ser\u00e3o ajustados e padronizados. - Relat\u00f3rios ser\u00e3o gerados em RMarkdown para cada arquivo CSV. Armazenamento dos Dados Raw - Os arquivos CSV originais ser\u00e3o armazenados no storage do Appwrite. Normaliza\u00e7\u00e3o e Processamento dos Dados - Os dados ser\u00e3o normalizados e processados no RStudio. - Dados processados (dados working) ser\u00e3o armazenados no MariaDB do Appwrite. Indexa\u00e7\u00e3o e Armazenamento de Dados Trusted - Um cont\u00eainer Docker do ElasticSearch ser\u00e1 configurado para indexa\u00e7\u00e3o e busca avan\u00e7ada. - Alternativamente, um cont\u00eainer Docker do ClickHouse ser\u00e1 configurado para armazenamento e an\u00e1lise de dados processados. - Dados do MariaDB ser\u00e3o indexados no ElasticSearch ou armazenados no ClickHouse. Constru\u00e7\u00e3o da Aplica\u00e7\u00e3o DataApp - Utilizando Streamlit, uma aplica\u00e7\u00e3o interativa ser\u00e1 desenvolvida para consumir dados do MariaDB, ElasticSearch e ClickHouse. - A aplica\u00e7\u00e3o ser\u00e1 dockerizada e gerenciada com Poetry. Processamento com Apache Spark - Apache Spark ser\u00e1 utilizado para realizar predi\u00e7\u00f5es com os dados em produ\u00e7\u00e3o.","title":"Arquitetura de Processamento de Dados"},{"location":"#o-que-e-backend-as-a-service-baas","text":"Backend as a Service (BaaS) \u00e9 um modelo de servi\u00e7o que fornece uma infraestrutura de backend pronta para uso, permitindo que desenvolvedores se concentrem no desenvolvimento do frontend e na l\u00f3gica de neg\u00f3cios. O BaaS oferece servi\u00e7os como autentica\u00e7\u00e3o, banco de dados, armazenamento de arquivos, notifica\u00e7\u00f5es push, entre outros, eliminando a necessidade de gerenciar servidores e infraestrutura.","title":"O que \u00e9 Backend as a Service (BaaS)?"},{"location":"#elasticsearch-vs-clickhouse","text":"","title":"ElasticSearch vs ClickHouse"},{"location":"#elasticsearch_1","text":"Descri\u00e7\u00e3o : Motor de busca e an\u00e1lise distribu\u00eddo, ideal para indexa\u00e7\u00e3o e busca avan\u00e7ada. Vantagens : - Excelente para buscas textuais e an\u00e1lises em tempo real. - Suporte robusto para consultas complexas e agrega\u00e7\u00f5es. Desvantagens : - Pode ser mais complexo de configurar e gerenciar para grandes volumes de dados.","title":"ElasticSearch"},{"location":"#clickhouse_1","text":"Descri\u00e7\u00e3o : Sistema de gerenciamento de banco de dados orientado a colunas, otimizado para consultas anal\u00edticas em tempo real. Vantagens : - Desempenho extremamente r\u00e1pido para consultas anal\u00edticas. - Otimizado para grandes volumes de dados e consultas de leitura intensiva. Desvantagens : - Menos adequado para buscas textuais complexas comparado ao ElasticSearch. Toda a arquitetura ser\u00e1 criada com Docker e rodar\u00e1 on-premise, mas poder\u00e1 ser facilmente integrada em uma nuvem ajustando os ambientes de conex\u00e3o (envs).","title":"ClickHouse"},{"location":"#ferramentas-e-tecnologias","text":"Ferramenta Descri\u00e7\u00e3o Uso RStudio IDE para R An\u00e1lise de dados, gera\u00e7\u00e3o de relat\u00f3rios RMarkdown Ferramenta para documentos din\u00e2micos Gera\u00e7\u00e3o de relat\u00f3rios Appwrite Plataforma de BaaS Armazenamento de dados raw e processados MariaDB Sistema de gerenciamento de banco de dados relacional Armazenamento de dados processados ElasticSearch Motor de busca e an\u00e1lise distribu\u00eddo Indexa\u00e7\u00e3o e busca avan\u00e7ada dos dados ClickHouse Sistema de gerenciamento de banco de dados orientado a colunas Armazenamento e an\u00e1lise de dados processados Streamlit Framework para cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas Constru\u00e7\u00e3o de uma aplica\u00e7\u00e3o de an\u00e1lise de dados (DataApp) Apache Spark Motor de an\u00e1lise unificada para processamento de dados em grande escala Processamento e predi\u00e7\u00e3o de dados Docker Plataforma para desenvolvimento, envio e execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres Dockeriza\u00e7\u00e3o da aplica\u00e7\u00e3o Streamlit, ElasticSearch e ClickHouse Poetry Gestor de pacotes e depend\u00eancias para projetos Python Gerenciamento de depend\u00eancias da aplica\u00e7\u00e3o Streamlit","title":"Ferramentas e Tecnologias"},{"location":"#mas-isso-nao-e-ferro-e-fogo","text":"Sinta-se a vontade para trazer novas tecnologias para o nosso m\u00f3dulo! Conte com os professores para analisarmos juntos novas solu\u00e7\u00f5es. Aqui vai o refactoring Guru para dar novas ideias \u00e0 voc\u00eas =) Refactoring Guru","title":"Mas isso n\u00e3o \u00e9 ferro e fogo!"},{"location":"arquitetura1/","text":"","title":"Arquitetura e Governan\u00e7a de Dados na Nuvem 1"},{"location":"arquitetura2/","text":"","title":"Arquitetura e Governan\u00e7a de Dados na Nuvem 2"},{"location":"datalakes/","text":"","title":"Data Lakes e Data Warehouses"},{"location":"datasourcing/","text":"Data Sourcing e Data Analysis com R Studio \u00b6 Autoestudos \u00b6 Nome Tipo Notebook de Datasourcing Documenta\u00e7\u00e3o Exploratory Data Analysis in R Programming Documenta\u00e7\u00e3o Slides \u00b6 Introdu\u00e7\u00e3o \u00e0 Linguagem R \u00b6 O que \u00e9 R? \u00b6 R \u00e9 uma linguagem de programa\u00e7\u00e3o e um ambiente de software livre para computa\u00e7\u00e3o estat\u00edstica e gr\u00e1ficos. Foi desenvolvido por Ross Ihaka e Robert Gentleman na Universidade de Auckland, Nova Zel\u00e2ndia, e \u00e9 amplamente utilizado por estat\u00edsticos e analistas de dados para desenvolver software estat\u00edstico e realizar an\u00e1lise de dados. Caracter\u00edsticas Principais \u00b6 Interativa : R \u00e9 uma linguagem interpretada, o que significa que voc\u00ea pode executar comandos um de cada vez e ver os resultados imediatamente. Extens\u00edvel : H\u00e1 uma vasta quantidade de pacotes adicionais dispon\u00edveis que podem ser instalados para estender a funcionalidade do R. Gr\u00e1ficos de Alta Qualidade : R possui ferramentas poderosas para a cria\u00e7\u00e3o de gr\u00e1ficos de alta qualidade e visualiza\u00e7\u00f5es de dados. Comunidade Ativa : A comunidade R \u00e9 grande e ativa, oferecendo suporte e recursos atrav\u00e9s de f\u00f3runs, blogs, e documenta\u00e7\u00e3o. Estrutura B\u00e1sica da Linguagem \u00b6 Objetos e Vari\u00e1veis \u00b6 R \u00e9 uma linguagem orientada a objetos, e quase tudo em R \u00e9 um objeto. Voc\u00ea pode criar vari\u00e1veis para armazenar dados e manipular esses dados usando v\u00e1rias fun\u00e7\u00f5es. # Atribui\u00e7\u00e3o de valores a vari\u00e1veis x <- 10 y <- 5 # Opera\u00e7\u00f5es aritm\u00e9ticas z <- x + y print ( z ) # Sa\u00edda: 15 Tipos de Dados \u00b6 R suporta v\u00e1rios tipos de dados b\u00e1sicos, incluindo: N\u00fameros : inteiros e n\u00fameros de ponto flutuante. Caracteres : strings. Vetores : uma sequ\u00eancia de dados do mesmo tipo. Matrizes : uma cole\u00e7\u00e3o bidimensional de dados. Data Frames : uma tabela de dados, onde cada coluna pode conter diferentes tipos de dados. Listas : uma cole\u00e7\u00e3o de objetos que podem ser de tipos diferentes. # Exemplos de tipos de dados num <- 42 char <- \"Ol\u00e1, mundo!\" vetor <- c ( 1 , 2 , 3 , 4 , 5 ) matriz <- matrix ( 1 : 9 , nrow = 3 ) df <- data.frame ( Nomes = c ( \"Ana\" , \"Pedro\" ), Idades = c ( 28 , 34 )) lista <- list ( num , char , vetor , matriz , df ) Fun\u00e7\u00f5es \u00b6 Fun\u00e7\u00f5es s\u00e3o uma parte essencial de R e permitem encapsular c\u00f3digo que pode ser reutilizado. Voc\u00ea pode usar fun\u00e7\u00f5es integradas ou criar suas pr\u00f3prias fun\u00e7\u00f5es. # Fun\u00e7\u00e3o simples para somar dois n\u00fameros soma <- function ( a , b ) { return ( a + b ) } resultado <- soma ( 3 , 4 ) print ( resultado ) # Sa\u00edda: 7 Controle de Fluxo \u00b6 R suporta estruturas de controle de fluxo, como condicionais ( if , else ) e loops ( for , while ). # Condicional if-else if ( x > y ) { print ( \"x \u00e9 maior que y\" ) } else { print ( \"x n\u00e3o \u00e9 maior que y\" ) } # Loop for for ( i in 1 : 5 ) { print ( i ) } Importa\u00e7\u00e3o e Manipula\u00e7\u00e3o de Dados \u00b6 Importa\u00e7\u00e3o de Dados \u00b6 R facilita a importa\u00e7\u00e3o de dados de v\u00e1rias fontes, como arquivos CSV, Excel, bancos de dados e APIs. # Importar dados de um arquivo CSV dados <- read.csv ( \"dados.csv\" ) # Visualizar as primeiras linhas do data frame head ( dados ) Manipula\u00e7\u00e3o de Dados \u00b6 A manipula\u00e7\u00e3o de dados em R pode ser realizada usando pacotes como dplyr e tidyr . # Carregar o pacote dplyr library ( dplyr ) # Selecionar colunas e filtrar linhas dados_filtrados <- dados %>% select ( Nome , Idade ) %>% filter ( Idade > 30 ) Visualiza\u00e7\u00e3o de Dados \u00b6 R possui pacotes poderosos para visualiza\u00e7\u00e3o de dados, como ggplot2 . # Carregar o pacote ggplot2 library ( ggplot2 ) # Criar um gr\u00e1fico de dispers\u00e3o ggplot ( dados , aes ( x = Idade , y = Salario )) + geom_point () + theme_minimal () + labs ( title = \"Idade vs. Sal\u00e1rio\" , x = \"Idade\" , y = \"Sal\u00e1rio\" ) Pacotes e Extens\u00f5es \u00b6 Uma das grandes vantagens de R \u00e9 a sua extensibilidade atrav\u00e9s de pacotes. Voc\u00ea pode instalar pacotes do CRAN (Comprehensive R Archive Network) para adicionar novas funcionalidades ao R. # Instalar e carregar um pacote install.packages ( \"tidyverse\" ) library ( tidyverse ) An\u00e1lise Explorat\u00f3ria Avan\u00e7ada com R \u00b6 Pr\u00e9-requisitos \u00b6 Conhecimento b\u00e1sico de R e RStudio Conhecimento b\u00e1sico de EDA Conte\u00fado da Aula \u00b6 Prepara\u00e7\u00e3o do Ambiente Importa\u00e7\u00e3o e Limpeza de Dados An\u00e1lise Univariada An\u00e1lise Bivariada An\u00e1lise Multivariada Visualiza\u00e7\u00e3o Avan\u00e7ada Estat\u00edsticas Avan\u00e7adas Prepara\u00e7\u00e3o do Ambiente \u00b6 Para come\u00e7ar, precisamos preparar nosso ambiente de trabalho instalando e carregando os pacotes necess\u00e1rios. # Instalar pacotes necess\u00e1rios install.packages ( c ( \"tidyverse\" , \"data.table\" , \"GGally\" , \"corrplot\" , \"gridExtra\" )) # Carregar pacotes library ( tidyverse ) library ( data.table ) library ( GGally ) library ( corrplot ) library ( gridExtra ) Importa\u00e7\u00e3o e Limpeza de Dados \u00b6 Nesta se\u00e7\u00e3o, vamos importar nossos dados e realizar a limpeza necess\u00e1ria. # Importar dados data <- fread ( \"path/to/your/data.csv\" ) # Exibir as primeiras linhas dos dados head ( data ) # Verificar dados faltantes sum ( is.na ( data )) # Limpeza de dados (exemplo: remover linhas com dados faltantes) data <- na.omit ( data ) An\u00e1lise Univariada \u00b6 A an\u00e1lise univariada envolve a descri\u00e7\u00e3o de cada vari\u00e1vel individualmente. # Distribui\u00e7\u00e3o de uma vari\u00e1vel num\u00e9rica ggplot ( data , aes ( x = variable )) + geom_histogram ( binwidth = 10 , fill = \"blue\" , color = \"black\" ) + theme_minimal () + labs ( title = \"Distribui\u00e7\u00e3o de Variable\" , x = \"Variable\" , y = \"Frequ\u00eancia\" ) # Medidas de tend\u00eancia central e dispers\u00e3o summary ( data $ variable ) An\u00e1lise Bivariada \u00b6 A an\u00e1lise bivariada examina a rela\u00e7\u00e3o entre duas vari\u00e1veis. # Scatter plot para duas vari\u00e1veis num\u00e9ricas ggplot ( data , aes ( x = variable1 , y = variable2 )) + geom_point () + theme_minimal () + labs ( title = \"Rela\u00e7\u00e3o entre Variable1 e Variable2\" , x = \"Variable1\" , y = \"Variable2\" ) # Boxplot para uma vari\u00e1vel categ\u00f3rica e uma num\u00e9rica ggplot ( data , aes ( x = categorical_variable , y = numeric_variable )) + geom_boxplot () + theme_minimal () + labs ( title = \"Boxplot de Categorical Variable e Numeric Variable\" , x = \"Categorical Variable\" , y = \"Numeric Variable\" ) An\u00e1lise Multivariada \u00b6 A an\u00e1lise multivariada considera m\u00faltiplas vari\u00e1veis simultaneamente. # Matriz de correla\u00e7\u00e3o cor_matrix <- cor ( data %>% select_if ( is.numeric )) corrplot ( cor_matrix , method = \"circle\" ) # Scatterplot matrix ggpairs ( data %>% select_if ( is.numeric )) Visualiza\u00e7\u00e3o Avan\u00e7ada \u00b6 Vamos explorar t\u00e9cnicas avan\u00e7adas de visualiza\u00e7\u00e3o para EDA. # Densidade 2D para grandes conjuntos de dados ggplot ( data , aes ( x = variable1 , y = variable2 )) + geom_bin2d () + scale_fill_gradient ( low = \"white\" , high = \"blue\" ) + theme_minimal () + labs ( title = \"Densidade 2D de Variable1 e Variable2\" , x = \"Variable1\" , y = \"Variable2\" ) # Facet wrap para visualiza\u00e7\u00e3o de subgrupos ggplot ( data , aes ( x = variable )) + geom_histogram ( binwidth = 10 , fill = \"blue\" , color = \"black\" ) + facet_wrap ( ~ categorical_variable ) + theme_minimal () + labs ( title = \"Distribui\u00e7\u00e3o de Variable por Categoria\" , x = \"Variable\" , y = \"Frequ\u00eancia\" ) Estat\u00edsticas Avan\u00e7adas \u00b6 Utilizaremos t\u00e9cnicas estat\u00edsticas avan\u00e7adas para aprofundar nossa an\u00e1lise. # Regress\u00e3o linear simples model <- lm ( variable2 ~ variable1 , data = data ) summary ( model ) # An\u00e1lise de componentes principais (PCA) pca <- prcomp ( data %>% select_if ( is.numeric ), scale = TRUE ) summary ( pca ) # Visualiza\u00e7\u00e3o dos componentes principais autoplot ( pca , data = data , colour = 'categorical_variable' ) Por que Fazer An\u00e1lise Explorat\u00f3ria Avan\u00e7ada com R em Dados Grandes? \u00b6 Introdu\u00e7\u00e3o \u00b6 A an\u00e1lise explorat\u00f3ria de dados (EDA) \u00e9 um passo fundamental no processo de an\u00e1lise de dados. Quando se trata de grandes volumes de dados, a import\u00e2ncia de uma EDA avan\u00e7ada se torna ainda mais crucial. A linguagem R \u00e9 uma das ferramentas mais poderosas e vers\u00e1teis dispon\u00edveis para realizar EDA em grandes conjuntos de dados. Aqui est\u00e3o alguns motivos pelos quais voc\u00ea deve considerar fazer an\u00e1lise explorat\u00f3ria avan\u00e7ada com R em dados grandes. 1. Ferramentas Poderosas de Manipula\u00e7\u00e3o de Dados \u00b6 dplyr e data.table \u00b6 R oferece pacotes como dplyr e data.table que s\u00e3o otimizados para manipula\u00e7\u00e3o de dados r\u00e1pida e eficiente, mesmo com conjuntos de dados grandes. Eles permitem realizar opera\u00e7\u00f5es complexas de transforma\u00e7\u00e3o de dados com uma sintaxe simples e intuitiva. # Exemplo de manipula\u00e7\u00e3o de dados com dplyr library ( dplyr ) dados_grandes %>% filter ( salario > 50000 ) %>% group_by ( departamento ) %>% summarise ( media_salario = mean ( salario , na.rm = TRUE )) 2. Visualiza\u00e7\u00e3o de Dados Escal\u00e1vel \u00b6 ggplot2 e plotly \u00b6 A visualiza\u00e7\u00e3o \u00e9 uma parte essencial da EDA. R, com pacotes como ggplot2 e plotly , permite criar visualiza\u00e7\u00f5es detalhadas e interativas que podem lidar com grandes volumes de dados. Estas visualiza\u00e7\u00f5es ajudam a identificar padr\u00f5es, tend\u00eancias e anomalias que n\u00e3o s\u00e3o facilmente vis\u00edveis em tabelas de dados. # Exemplo de visualiza\u00e7\u00e3o com ggplot2 library ( ggplot2 ) ggplot ( dados_grandes , aes ( x = idade , y = salario )) + geom_point ( alpha = 0.5 ) + theme_minimal () + labs ( title = \"Rela\u00e7\u00e3o entre Idade e Sal\u00e1rio\" ) 3. Suporte para Computa\u00e7\u00e3o Paralela \u00b6 parallel e future \u00b6 Para conjuntos de dados muito grandes, a computa\u00e7\u00e3o paralela pode acelerar significativamente o processamento. R possui suporte nativo para computa\u00e7\u00e3o paralela atrav\u00e9s de pacotes como parallel e future , permitindo distribuir tarefas em m\u00faltiplos n\u00facleos de CPU. # Exemplo de computa\u00e7\u00e3o paralela com future library ( future ) plan ( multisession , workers = 4 ) resultados <- future_lapply ( 1 : 10 , function ( x ) sum ( rnorm ( 1e6 ))) 4. Integra\u00e7\u00e3o com Big Data \u00b6 sparklyr e DBI \u00b6 R pode se integrar facilmente com tecnologias de Big Data como Apache Spark atrav\u00e9s do pacote sparklyr , e tamb\u00e9m com bancos de dados SQL atrav\u00e9s do pacote DBI . Isso permite que voc\u00ea realize EDA em dados armazenados em sistemas distribu\u00eddos ou em bancos de dados de grande escala. Exemplo de Integra\u00e7\u00e3o com Spark usando Docker \u00b6 Passo 1: Configurar o Ambiente Docker \u00b6 Crie um arquivo docker-compose.yml para configurar um cluster Spark com Hadoop. version : '3.7' services : spark-master : image : bde2020/spark-master:latest container_name : spark-master ports : - \"8080:8080\" - \"7077:7077\" environment : - INIT_DAEMON_STEP=setup_spark networks : - spark spark-worker-1 : image : bde2020/spark-worker:latest container_name : spark-worker-1 depends_on : - spark-master environment : - \"SPARK_MASTER=spark://spark-master:7077\" - INIT_DAEMON_STEP=setup_worker networks : - spark networks : spark : driver : bridge Passo 2: Iniciar o Cluster Spark \u00b6 Inicie o cluster Spark usando Docker Compose. docker-compose up -d Passo 3: Conectar ao Spark no R \u00b6 Utilize o pacote sparklyr para conectar ao cluster Spark. # Instalar e carregar pacotes necess\u00e1rios install.packages ( \"sparklyr\" ) library ( sparklyr ) # Conectar ao cluster Spark sc <- spark_connect ( master = \"spark://localhost:7077\" ) # Copiar dados para o Spark dados_spark <- copy_to ( sc , dados_grandes , \"dados_grandes_tbl\" ) # Realizar opera\u00e7\u00f5es no Spark dados_spark %>% filter ( salario > 50000 ) %>% group_by ( departamento ) %>% summarise ( media_salario = mean ( salario , na.rm = TRUE )) %>% collect () Passo 4: Desconectar do Spark \u00b6 Ap\u00f3s a an\u00e1lise, desconecte do cluster Spark. spark_disconnect ( sc ) 5. Capacidades Estat\u00edsticas Avan\u00e7adas \u00b6 caret e mlr \u00b6 R \u00e9 amplamente reconhecido por suas capacidades estat\u00edsticas e de machine learning. Pacotes como caret e mlr permitem realizar an\u00e1lises estat\u00edsticas avan\u00e7adas e aplicar algoritmos de machine learning para descobrir insights profundos em grandes volumes de dados. # Exemplo de an\u00e1lise com caret library ( caret ) modelo <- train ( salario ~ . , data = dados_grandes , method = \"lm\" ) print ( modelo ) Conclus\u00e3o \u00b6 Nesta aula, exploramos t\u00e9cnicas avan\u00e7adas de An\u00e1lise Explorat\u00f3ria de Dados (EDA) usando R. Aprendemos a preparar o ambiente, importar e limpar dados, realizar an\u00e1lises univariadas, bivariadas e multivariadas, criar visualiza\u00e7\u00f5es avan\u00e7adas e aplicar estat\u00edsticas avan\u00e7adas. Com essas habilidades, voc\u00ea estar\u00e1 bem equipado para realizar EDA de maneira eficaz e profunda. Refer\u00eancias \u00b6 Notebook de Datasourcing Exploratory Data Analysis in R Programming R for Data Science The Comprehensive R Archive Network (CRAN) R Documentation R for Data Science Data Manipulation with dplyr Efficient R programming with data.table ggplot2: Elegant Graphics for Data Analysis Apache Spark Integration with R M\u00e3o na Massa! - An\u00e1lise Explorat\u00f3ria de Dados com o Conjunto de Dados Wine \u00b6 Introdu\u00e7\u00e3o \u00b6 O conjunto de dados de vinhos ( wine ) \u00e9 amplamente utilizado para demonstra\u00e7\u00f5es de t\u00e9cnicas de an\u00e1lise de dados e machine learning. Ele cont\u00e9m informa\u00e7\u00f5es qu\u00edmicas sobre diferentes tipos de vinhos e a qualidade atribu\u00edda a cada um. Neste tutorial, vamos realizar uma An\u00e1lise Explorat\u00f3ria de Dados (EDA) completa utilizando a linguagem R. Passo 1: Prepara\u00e7\u00e3o do Ambiente \u00b6 Primeiro, vamos preparar nosso ambiente de trabalho, instalando e carregando os pacotes necess\u00e1rios. # Instalar pacotes necess\u00e1rios install.packages ( c ( \"tidyverse\" , \"GGally\" , \"corrplot\" , \"gridExtra\" )) # Carregar pacotes library ( tidyverse ) library ( GGally ) library ( corrplot ) library ( gridExtra ) Passo 2: Carregar os Dados \u00b6 Vamos carregar o conjunto de dados wine . Supondo que o arquivo esteja em formato CSV, usaremos a fun\u00e7\u00e3o read.csv . # Carregar os dados wine_data <- read.csv ( \"path/to/wine.csv\" ) # Exibir as primeiras linhas do data frame head ( wine_data ) Passo 3: Entender a Estrutura dos Dados \u00b6 Examinaremos a estrutura dos dados para entender suas caracter\u00edsticas b\u00e1sicas. # Estrutura dos dados str ( wine_data ) # Resumo estat\u00edstico das vari\u00e1veis summary ( wine_data ) Passo 4: Verificar Dados Faltantes \u00b6 Verificaremos se h\u00e1 dados faltantes no conjunto de dados. # Verificar dados faltantes sum ( is.na ( wine_data )) Passo 5: An\u00e1lise Univariada \u00b6 Realizaremos a an\u00e1lise de cada vari\u00e1vel individualmente. Distribui\u00e7\u00e3o da Qualidade do Vinho \u00b6 # Histograma da vari\u00e1vel 'quality' ggplot ( wine_data , aes ( x = quality )) + geom_histogram ( binwidth = 1 , fill = \"blue\" , color = \"black\" ) + theme_minimal () + labs ( title = \"Distribui\u00e7\u00e3o da Qualidade do Vinho\" , x = \"Qualidade\" , y = \"Frequ\u00eancia\" ) Distribui\u00e7\u00e3o de Vari\u00e1veis Num\u00e9ricas \u00b6 # Histograma para cada vari\u00e1vel num\u00e9rica numeric_vars <- wine_data %>% select ( - quality ) p <- lapply ( names ( numeric_vars ), function ( var ) { ggplot ( wine_data , aes_string ( x = var )) + geom_histogram ( fill = \"blue\" , color = \"black\" , bins = 30 ) + theme_minimal () + labs ( title = paste ( \"Distribui\u00e7\u00e3o de\" , var ), x = var , y = \"Frequ\u00eancia\" ) }) grid.arrange ( grobs = p , ncol = 3 ) Passo 6: An\u00e1lise Bivariada \u00b6 Examinaremos as rela\u00e7\u00f5es entre pares de vari\u00e1veis. Rela\u00e7\u00e3o entre \u00c1lcool e Qualidade \u00b6 # Scatter plot entre 'alcohol' e 'quality' ggplot ( wine_data , aes ( x = alcohol , y = quality )) + geom_point ( alpha = 0.5 ) + theme_minimal () + labs ( title = \"Rela\u00e7\u00e3o entre \u00c1lcool e Qualidade\" , x = \"\u00c1lcool\" , y = \"Qualidade\" ) Boxplot da Qualidade por Tipo de Vinho \u00b6 # Supondo que h\u00e1 uma coluna 'type' indicando o tipo de vinho ggplot ( wine_data , aes ( x = factor ( quality ), y = alcohol , fill = factor ( quality ))) + geom_boxplot () + theme_minimal () + labs ( title = \"Boxplot da Qualidade por Tipo de Vinho\" , x = \"Qualidade\" , y = \"\u00c1lcool\" ) Passo 7: An\u00e1lise Multivariada \u00b6 Analisaremos m\u00faltiplas vari\u00e1veis simultaneamente. Matriz de Correla\u00e7\u00e3o \u00b6 # Matriz de correla\u00e7\u00e3o cor_matrix <- cor ( wine_data %>% select_if ( is.numeric )) corrplot ( cor_matrix , method = \"circle\" ) Scatterplot Matrix \u00b6 # Scatterplot matrix ggpairs ( wine_data %>% select_if ( is.numeric )) Passo 8: Conclus\u00f5es e Insights \u00b6 Ap\u00f3s a an\u00e1lise, resumimos nossos principais achados: A distribui\u00e7\u00e3o da qualidade dos vinhos \u00e9... A rela\u00e7\u00e3o entre o teor de \u00e1lcool e a qualidade \u00e9... Vari\u00e1veis como \u00e1cido c\u00edtrico e pH apresentam correla\u00e7\u00e3o... Refer\u00eancias \u00b6 Documenta\u00e7\u00e3o do ggplot2 Guia de Introdu\u00e7\u00e3o ao dplyr Qual a Miss\u00e3o para o Artefato? \u00b6 Os grupos dever\u00e3o realizar uma An\u00e1lise Explorat\u00f3ria Avan\u00e7ada nos dados que foram fornecidos. Esta an\u00e1lise deve incluir, mas n\u00e3o se limitar a: Entender a estrutura dos dados e suas caracter\u00edsticas b\u00e1sicas. Realizar uma an\u00e1lise univariada de todas as vari\u00e1veis. Explorar rela\u00e7\u00f5es bivariadas entre vari\u00e1veis para identificar poss\u00edveis correla\u00e7\u00f5es. Conduzir uma an\u00e1lise multivariada para entender intera\u00e7\u00f5es complexas entre vari\u00e1veis. Utilizar visualiza\u00e7\u00f5es para ilustrar as descobertas e insights obtidos. Uso de Computa\u00e7\u00e3o Distribu\u00edda com Spark \u00b6 Caso o conjunto de dados seja muito extenso e torne o processamento em um \u00fanico computador invi\u00e1vel, os grupos dever\u00e3o utilizar o Apache Spark como solu\u00e7\u00e3o de computa\u00e7\u00e3o distribu\u00edda. O Spark permite manipular e processar grandes volumes de dados de maneira eficiente, distribuindo as tarefas em m\u00faltiplos n\u00f3s de computa\u00e7\u00e3o. Utilizem essas ferramentas e t\u00e9cnicas para garantir que a an\u00e1lise seja completa e eficiente, mesmo com conjuntos de dados volumosos. O objetivo final \u00e9 extrair insights valiosos dos dados fornecidos e apresentar esses insights de forma clara e compreens\u00edvel.","title":"Data Sourcing e Data Analysis com R Studio"},{"location":"datasourcing/#data-sourcing-e-data-analysis-com-r-studio","text":"","title":"Data Sourcing e Data Analysis com R Studio"},{"location":"datasourcing/#autoestudos","text":"Nome Tipo Notebook de Datasourcing Documenta\u00e7\u00e3o Exploratory Data Analysis in R Programming Documenta\u00e7\u00e3o","title":"Autoestudos"},{"location":"datasourcing/#slides","text":"","title":"Slides"},{"location":"datasourcing/#introducao-a-linguagem-r","text":"","title":"Introdu\u00e7\u00e3o \u00e0 Linguagem R"},{"location":"datasourcing/#o-que-e-r","text":"R \u00e9 uma linguagem de programa\u00e7\u00e3o e um ambiente de software livre para computa\u00e7\u00e3o estat\u00edstica e gr\u00e1ficos. Foi desenvolvido por Ross Ihaka e Robert Gentleman na Universidade de Auckland, Nova Zel\u00e2ndia, e \u00e9 amplamente utilizado por estat\u00edsticos e analistas de dados para desenvolver software estat\u00edstico e realizar an\u00e1lise de dados.","title":"O que \u00e9 R?"},{"location":"datasourcing/#caracteristicas-principais","text":"Interativa : R \u00e9 uma linguagem interpretada, o que significa que voc\u00ea pode executar comandos um de cada vez e ver os resultados imediatamente. Extens\u00edvel : H\u00e1 uma vasta quantidade de pacotes adicionais dispon\u00edveis que podem ser instalados para estender a funcionalidade do R. Gr\u00e1ficos de Alta Qualidade : R possui ferramentas poderosas para a cria\u00e7\u00e3o de gr\u00e1ficos de alta qualidade e visualiza\u00e7\u00f5es de dados. Comunidade Ativa : A comunidade R \u00e9 grande e ativa, oferecendo suporte e recursos atrav\u00e9s de f\u00f3runs, blogs, e documenta\u00e7\u00e3o.","title":"Caracter\u00edsticas Principais"},{"location":"datasourcing/#estrutura-basica-da-linguagem","text":"","title":"Estrutura B\u00e1sica da Linguagem"},{"location":"datasourcing/#objetos-e-variaveis","text":"R \u00e9 uma linguagem orientada a objetos, e quase tudo em R \u00e9 um objeto. Voc\u00ea pode criar vari\u00e1veis para armazenar dados e manipular esses dados usando v\u00e1rias fun\u00e7\u00f5es. # Atribui\u00e7\u00e3o de valores a vari\u00e1veis x <- 10 y <- 5 # Opera\u00e7\u00f5es aritm\u00e9ticas z <- x + y print ( z ) # Sa\u00edda: 15","title":"Objetos e Vari\u00e1veis"},{"location":"datasourcing/#tipos-de-dados","text":"R suporta v\u00e1rios tipos de dados b\u00e1sicos, incluindo: N\u00fameros : inteiros e n\u00fameros de ponto flutuante. Caracteres : strings. Vetores : uma sequ\u00eancia de dados do mesmo tipo. Matrizes : uma cole\u00e7\u00e3o bidimensional de dados. Data Frames : uma tabela de dados, onde cada coluna pode conter diferentes tipos de dados. Listas : uma cole\u00e7\u00e3o de objetos que podem ser de tipos diferentes. # Exemplos de tipos de dados num <- 42 char <- \"Ol\u00e1, mundo!\" vetor <- c ( 1 , 2 , 3 , 4 , 5 ) matriz <- matrix ( 1 : 9 , nrow = 3 ) df <- data.frame ( Nomes = c ( \"Ana\" , \"Pedro\" ), Idades = c ( 28 , 34 )) lista <- list ( num , char , vetor , matriz , df )","title":"Tipos de Dados"},{"location":"datasourcing/#funcoes","text":"Fun\u00e7\u00f5es s\u00e3o uma parte essencial de R e permitem encapsular c\u00f3digo que pode ser reutilizado. Voc\u00ea pode usar fun\u00e7\u00f5es integradas ou criar suas pr\u00f3prias fun\u00e7\u00f5es. # Fun\u00e7\u00e3o simples para somar dois n\u00fameros soma <- function ( a , b ) { return ( a + b ) } resultado <- soma ( 3 , 4 ) print ( resultado ) # Sa\u00edda: 7","title":"Fun\u00e7\u00f5es"},{"location":"datasourcing/#controle-de-fluxo","text":"R suporta estruturas de controle de fluxo, como condicionais ( if , else ) e loops ( for , while ). # Condicional if-else if ( x > y ) { print ( \"x \u00e9 maior que y\" ) } else { print ( \"x n\u00e3o \u00e9 maior que y\" ) } # Loop for for ( i in 1 : 5 ) { print ( i ) }","title":"Controle de Fluxo"},{"location":"datasourcing/#importacao-e-manipulacao-de-dados","text":"","title":"Importa\u00e7\u00e3o e Manipula\u00e7\u00e3o de Dados"},{"location":"datasourcing/#importacao-de-dados","text":"R facilita a importa\u00e7\u00e3o de dados de v\u00e1rias fontes, como arquivos CSV, Excel, bancos de dados e APIs. # Importar dados de um arquivo CSV dados <- read.csv ( \"dados.csv\" ) # Visualizar as primeiras linhas do data frame head ( dados )","title":"Importa\u00e7\u00e3o de Dados"},{"location":"datasourcing/#manipulacao-de-dados","text":"A manipula\u00e7\u00e3o de dados em R pode ser realizada usando pacotes como dplyr e tidyr . # Carregar o pacote dplyr library ( dplyr ) # Selecionar colunas e filtrar linhas dados_filtrados <- dados %>% select ( Nome , Idade ) %>% filter ( Idade > 30 )","title":"Manipula\u00e7\u00e3o de Dados"},{"location":"datasourcing/#visualizacao-de-dados","text":"R possui pacotes poderosos para visualiza\u00e7\u00e3o de dados, como ggplot2 . # Carregar o pacote ggplot2 library ( ggplot2 ) # Criar um gr\u00e1fico de dispers\u00e3o ggplot ( dados , aes ( x = Idade , y = Salario )) + geom_point () + theme_minimal () + labs ( title = \"Idade vs. Sal\u00e1rio\" , x = \"Idade\" , y = \"Sal\u00e1rio\" )","title":"Visualiza\u00e7\u00e3o de Dados"},{"location":"datasourcing/#pacotes-e-extensoes","text":"Uma das grandes vantagens de R \u00e9 a sua extensibilidade atrav\u00e9s de pacotes. Voc\u00ea pode instalar pacotes do CRAN (Comprehensive R Archive Network) para adicionar novas funcionalidades ao R. # Instalar e carregar um pacote install.packages ( \"tidyverse\" ) library ( tidyverse )","title":"Pacotes e Extens\u00f5es"},{"location":"datasourcing/#analise-exploratoria-avancada-com-r","text":"","title":"An\u00e1lise Explorat\u00f3ria Avan\u00e7ada com R"},{"location":"datasourcing/#pre-requisitos","text":"Conhecimento b\u00e1sico de R e RStudio Conhecimento b\u00e1sico de EDA","title":"Pr\u00e9-requisitos"},{"location":"datasourcing/#conteudo-da-aula","text":"Prepara\u00e7\u00e3o do Ambiente Importa\u00e7\u00e3o e Limpeza de Dados An\u00e1lise Univariada An\u00e1lise Bivariada An\u00e1lise Multivariada Visualiza\u00e7\u00e3o Avan\u00e7ada Estat\u00edsticas Avan\u00e7adas","title":"Conte\u00fado da Aula"},{"location":"datasourcing/#preparacao-do-ambiente","text":"Para come\u00e7ar, precisamos preparar nosso ambiente de trabalho instalando e carregando os pacotes necess\u00e1rios. # Instalar pacotes necess\u00e1rios install.packages ( c ( \"tidyverse\" , \"data.table\" , \"GGally\" , \"corrplot\" , \"gridExtra\" )) # Carregar pacotes library ( tidyverse ) library ( data.table ) library ( GGally ) library ( corrplot ) library ( gridExtra )","title":"Prepara\u00e7\u00e3o do Ambiente"},{"location":"datasourcing/#importacao-e-limpeza-de-dados","text":"Nesta se\u00e7\u00e3o, vamos importar nossos dados e realizar a limpeza necess\u00e1ria. # Importar dados data <- fread ( \"path/to/your/data.csv\" ) # Exibir as primeiras linhas dos dados head ( data ) # Verificar dados faltantes sum ( is.na ( data )) # Limpeza de dados (exemplo: remover linhas com dados faltantes) data <- na.omit ( data )","title":"Importa\u00e7\u00e3o e Limpeza de Dados"},{"location":"datasourcing/#analise-univariada","text":"A an\u00e1lise univariada envolve a descri\u00e7\u00e3o de cada vari\u00e1vel individualmente. # Distribui\u00e7\u00e3o de uma vari\u00e1vel num\u00e9rica ggplot ( data , aes ( x = variable )) + geom_histogram ( binwidth = 10 , fill = \"blue\" , color = \"black\" ) + theme_minimal () + labs ( title = \"Distribui\u00e7\u00e3o de Variable\" , x = \"Variable\" , y = \"Frequ\u00eancia\" ) # Medidas de tend\u00eancia central e dispers\u00e3o summary ( data $ variable )","title":"An\u00e1lise Univariada"},{"location":"datasourcing/#analise-bivariada","text":"A an\u00e1lise bivariada examina a rela\u00e7\u00e3o entre duas vari\u00e1veis. # Scatter plot para duas vari\u00e1veis num\u00e9ricas ggplot ( data , aes ( x = variable1 , y = variable2 )) + geom_point () + theme_minimal () + labs ( title = \"Rela\u00e7\u00e3o entre Variable1 e Variable2\" , x = \"Variable1\" , y = \"Variable2\" ) # Boxplot para uma vari\u00e1vel categ\u00f3rica e uma num\u00e9rica ggplot ( data , aes ( x = categorical_variable , y = numeric_variable )) + geom_boxplot () + theme_minimal () + labs ( title = \"Boxplot de Categorical Variable e Numeric Variable\" , x = \"Categorical Variable\" , y = \"Numeric Variable\" )","title":"An\u00e1lise Bivariada"},{"location":"datasourcing/#analise-multivariada","text":"A an\u00e1lise multivariada considera m\u00faltiplas vari\u00e1veis simultaneamente. # Matriz de correla\u00e7\u00e3o cor_matrix <- cor ( data %>% select_if ( is.numeric )) corrplot ( cor_matrix , method = \"circle\" ) # Scatterplot matrix ggpairs ( data %>% select_if ( is.numeric ))","title":"An\u00e1lise Multivariada"},{"location":"datasourcing/#visualizacao-avancada","text":"Vamos explorar t\u00e9cnicas avan\u00e7adas de visualiza\u00e7\u00e3o para EDA. # Densidade 2D para grandes conjuntos de dados ggplot ( data , aes ( x = variable1 , y = variable2 )) + geom_bin2d () + scale_fill_gradient ( low = \"white\" , high = \"blue\" ) + theme_minimal () + labs ( title = \"Densidade 2D de Variable1 e Variable2\" , x = \"Variable1\" , y = \"Variable2\" ) # Facet wrap para visualiza\u00e7\u00e3o de subgrupos ggplot ( data , aes ( x = variable )) + geom_histogram ( binwidth = 10 , fill = \"blue\" , color = \"black\" ) + facet_wrap ( ~ categorical_variable ) + theme_minimal () + labs ( title = \"Distribui\u00e7\u00e3o de Variable por Categoria\" , x = \"Variable\" , y = \"Frequ\u00eancia\" )","title":"Visualiza\u00e7\u00e3o Avan\u00e7ada"},{"location":"datasourcing/#estatisticas-avancadas","text":"Utilizaremos t\u00e9cnicas estat\u00edsticas avan\u00e7adas para aprofundar nossa an\u00e1lise. # Regress\u00e3o linear simples model <- lm ( variable2 ~ variable1 , data = data ) summary ( model ) # An\u00e1lise de componentes principais (PCA) pca <- prcomp ( data %>% select_if ( is.numeric ), scale = TRUE ) summary ( pca ) # Visualiza\u00e7\u00e3o dos componentes principais autoplot ( pca , data = data , colour = 'categorical_variable' )","title":"Estat\u00edsticas Avan\u00e7adas"},{"location":"datasourcing/#por-que-fazer-analise-exploratoria-avancada-com-r-em-dados-grandes","text":"","title":"Por que Fazer An\u00e1lise Explorat\u00f3ria Avan\u00e7ada com R em Dados Grandes?"},{"location":"datasourcing/#introducao","text":"A an\u00e1lise explorat\u00f3ria de dados (EDA) \u00e9 um passo fundamental no processo de an\u00e1lise de dados. Quando se trata de grandes volumes de dados, a import\u00e2ncia de uma EDA avan\u00e7ada se torna ainda mais crucial. A linguagem R \u00e9 uma das ferramentas mais poderosas e vers\u00e1teis dispon\u00edveis para realizar EDA em grandes conjuntos de dados. Aqui est\u00e3o alguns motivos pelos quais voc\u00ea deve considerar fazer an\u00e1lise explorat\u00f3ria avan\u00e7ada com R em dados grandes.","title":"Introdu\u00e7\u00e3o"},{"location":"datasourcing/#1-ferramentas-poderosas-de-manipulacao-de-dados","text":"","title":"1. Ferramentas Poderosas de Manipula\u00e7\u00e3o de Dados"},{"location":"datasourcing/#dplyr-e-datatable","text":"R oferece pacotes como dplyr e data.table que s\u00e3o otimizados para manipula\u00e7\u00e3o de dados r\u00e1pida e eficiente, mesmo com conjuntos de dados grandes. Eles permitem realizar opera\u00e7\u00f5es complexas de transforma\u00e7\u00e3o de dados com uma sintaxe simples e intuitiva. # Exemplo de manipula\u00e7\u00e3o de dados com dplyr library ( dplyr ) dados_grandes %>% filter ( salario > 50000 ) %>% group_by ( departamento ) %>% summarise ( media_salario = mean ( salario , na.rm = TRUE ))","title":"dplyr e data.table"},{"location":"datasourcing/#2-visualizacao-de-dados-escalavel","text":"","title":"2. Visualiza\u00e7\u00e3o de Dados Escal\u00e1vel"},{"location":"datasourcing/#ggplot2-e-plotly","text":"A visualiza\u00e7\u00e3o \u00e9 uma parte essencial da EDA. R, com pacotes como ggplot2 e plotly , permite criar visualiza\u00e7\u00f5es detalhadas e interativas que podem lidar com grandes volumes de dados. Estas visualiza\u00e7\u00f5es ajudam a identificar padr\u00f5es, tend\u00eancias e anomalias que n\u00e3o s\u00e3o facilmente vis\u00edveis em tabelas de dados. # Exemplo de visualiza\u00e7\u00e3o com ggplot2 library ( ggplot2 ) ggplot ( dados_grandes , aes ( x = idade , y = salario )) + geom_point ( alpha = 0.5 ) + theme_minimal () + labs ( title = \"Rela\u00e7\u00e3o entre Idade e Sal\u00e1rio\" )","title":"ggplot2 e plotly"},{"location":"datasourcing/#3-suporte-para-computacao-paralela","text":"","title":"3. Suporte para Computa\u00e7\u00e3o Paralela"},{"location":"datasourcing/#parallel-e-future","text":"Para conjuntos de dados muito grandes, a computa\u00e7\u00e3o paralela pode acelerar significativamente o processamento. R possui suporte nativo para computa\u00e7\u00e3o paralela atrav\u00e9s de pacotes como parallel e future , permitindo distribuir tarefas em m\u00faltiplos n\u00facleos de CPU. # Exemplo de computa\u00e7\u00e3o paralela com future library ( future ) plan ( multisession , workers = 4 ) resultados <- future_lapply ( 1 : 10 , function ( x ) sum ( rnorm ( 1e6 )))","title":"parallel e future"},{"location":"datasourcing/#4-integracao-com-big-data","text":"","title":"4. Integra\u00e7\u00e3o com Big Data"},{"location":"datasourcing/#sparklyr-e-dbi","text":"R pode se integrar facilmente com tecnologias de Big Data como Apache Spark atrav\u00e9s do pacote sparklyr , e tamb\u00e9m com bancos de dados SQL atrav\u00e9s do pacote DBI . Isso permite que voc\u00ea realize EDA em dados armazenados em sistemas distribu\u00eddos ou em bancos de dados de grande escala.","title":"sparklyr e DBI"},{"location":"datasourcing/#exemplo-de-integracao-com-spark-usando-docker","text":"","title":"Exemplo de Integra\u00e7\u00e3o com Spark usando Docker"},{"location":"datasourcing/#passo-1-configurar-o-ambiente-docker","text":"Crie um arquivo docker-compose.yml para configurar um cluster Spark com Hadoop. version : '3.7' services : spark-master : image : bde2020/spark-master:latest container_name : spark-master ports : - \"8080:8080\" - \"7077:7077\" environment : - INIT_DAEMON_STEP=setup_spark networks : - spark spark-worker-1 : image : bde2020/spark-worker:latest container_name : spark-worker-1 depends_on : - spark-master environment : - \"SPARK_MASTER=spark://spark-master:7077\" - INIT_DAEMON_STEP=setup_worker networks : - spark networks : spark : driver : bridge","title":"Passo 1: Configurar o Ambiente Docker"},{"location":"datasourcing/#passo-2-iniciar-o-cluster-spark","text":"Inicie o cluster Spark usando Docker Compose. docker-compose up -d","title":"Passo 2: Iniciar o Cluster Spark"},{"location":"datasourcing/#passo-3-conectar-ao-spark-no-r","text":"Utilize o pacote sparklyr para conectar ao cluster Spark. # Instalar e carregar pacotes necess\u00e1rios install.packages ( \"sparklyr\" ) library ( sparklyr ) # Conectar ao cluster Spark sc <- spark_connect ( master = \"spark://localhost:7077\" ) # Copiar dados para o Spark dados_spark <- copy_to ( sc , dados_grandes , \"dados_grandes_tbl\" ) # Realizar opera\u00e7\u00f5es no Spark dados_spark %>% filter ( salario > 50000 ) %>% group_by ( departamento ) %>% summarise ( media_salario = mean ( salario , na.rm = TRUE )) %>% collect ()","title":"Passo 3: Conectar ao Spark no R"},{"location":"datasourcing/#passo-4-desconectar-do-spark","text":"Ap\u00f3s a an\u00e1lise, desconecte do cluster Spark. spark_disconnect ( sc )","title":"Passo 4: Desconectar do Spark"},{"location":"datasourcing/#5-capacidades-estatisticas-avancadas","text":"","title":"5. Capacidades Estat\u00edsticas Avan\u00e7adas"},{"location":"datasourcing/#caret-e-mlr","text":"R \u00e9 amplamente reconhecido por suas capacidades estat\u00edsticas e de machine learning. Pacotes como caret e mlr permitem realizar an\u00e1lises estat\u00edsticas avan\u00e7adas e aplicar algoritmos de machine learning para descobrir insights profundos em grandes volumes de dados. # Exemplo de an\u00e1lise com caret library ( caret ) modelo <- train ( salario ~ . , data = dados_grandes , method = \"lm\" ) print ( modelo )","title":"caret e mlr"},{"location":"datasourcing/#conclusao","text":"Nesta aula, exploramos t\u00e9cnicas avan\u00e7adas de An\u00e1lise Explorat\u00f3ria de Dados (EDA) usando R. Aprendemos a preparar o ambiente, importar e limpar dados, realizar an\u00e1lises univariadas, bivariadas e multivariadas, criar visualiza\u00e7\u00f5es avan\u00e7adas e aplicar estat\u00edsticas avan\u00e7adas. Com essas habilidades, voc\u00ea estar\u00e1 bem equipado para realizar EDA de maneira eficaz e profunda.","title":"Conclus\u00e3o"},{"location":"datasourcing/#referencias","text":"Notebook de Datasourcing Exploratory Data Analysis in R Programming R for Data Science The Comprehensive R Archive Network (CRAN) R Documentation R for Data Science Data Manipulation with dplyr Efficient R programming with data.table ggplot2: Elegant Graphics for Data Analysis Apache Spark Integration with R","title":"Refer\u00eancias"},{"location":"datasourcing/#mao-na-massa-analise-exploratoria-de-dados-com-o-conjunto-de-dados-wine","text":"","title":"M\u00e3o na Massa! - An\u00e1lise Explorat\u00f3ria de Dados com o Conjunto de Dados Wine"},{"location":"datasourcing/#introducao_1","text":"O conjunto de dados de vinhos ( wine ) \u00e9 amplamente utilizado para demonstra\u00e7\u00f5es de t\u00e9cnicas de an\u00e1lise de dados e machine learning. Ele cont\u00e9m informa\u00e7\u00f5es qu\u00edmicas sobre diferentes tipos de vinhos e a qualidade atribu\u00edda a cada um. Neste tutorial, vamos realizar uma An\u00e1lise Explorat\u00f3ria de Dados (EDA) completa utilizando a linguagem R.","title":"Introdu\u00e7\u00e3o"},{"location":"datasourcing/#passo-1-preparacao-do-ambiente","text":"Primeiro, vamos preparar nosso ambiente de trabalho, instalando e carregando os pacotes necess\u00e1rios. # Instalar pacotes necess\u00e1rios install.packages ( c ( \"tidyverse\" , \"GGally\" , \"corrplot\" , \"gridExtra\" )) # Carregar pacotes library ( tidyverse ) library ( GGally ) library ( corrplot ) library ( gridExtra )","title":"Passo 1: Prepara\u00e7\u00e3o do Ambiente"},{"location":"datasourcing/#passo-2-carregar-os-dados","text":"Vamos carregar o conjunto de dados wine . Supondo que o arquivo esteja em formato CSV, usaremos a fun\u00e7\u00e3o read.csv . # Carregar os dados wine_data <- read.csv ( \"path/to/wine.csv\" ) # Exibir as primeiras linhas do data frame head ( wine_data )","title":"Passo 2: Carregar os Dados"},{"location":"datasourcing/#passo-3-entender-a-estrutura-dos-dados","text":"Examinaremos a estrutura dos dados para entender suas caracter\u00edsticas b\u00e1sicas. # Estrutura dos dados str ( wine_data ) # Resumo estat\u00edstico das vari\u00e1veis summary ( wine_data )","title":"Passo 3: Entender a Estrutura dos Dados"},{"location":"datasourcing/#passo-4-verificar-dados-faltantes","text":"Verificaremos se h\u00e1 dados faltantes no conjunto de dados. # Verificar dados faltantes sum ( is.na ( wine_data ))","title":"Passo 4: Verificar Dados Faltantes"},{"location":"datasourcing/#passo-5-analise-univariada","text":"Realizaremos a an\u00e1lise de cada vari\u00e1vel individualmente.","title":"Passo 5: An\u00e1lise Univariada"},{"location":"datasourcing/#distribuicao-da-qualidade-do-vinho","text":"# Histograma da vari\u00e1vel 'quality' ggplot ( wine_data , aes ( x = quality )) + geom_histogram ( binwidth = 1 , fill = \"blue\" , color = \"black\" ) + theme_minimal () + labs ( title = \"Distribui\u00e7\u00e3o da Qualidade do Vinho\" , x = \"Qualidade\" , y = \"Frequ\u00eancia\" )","title":"Distribui\u00e7\u00e3o da Qualidade do Vinho"},{"location":"datasourcing/#distribuicao-de-variaveis-numericas","text":"# Histograma para cada vari\u00e1vel num\u00e9rica numeric_vars <- wine_data %>% select ( - quality ) p <- lapply ( names ( numeric_vars ), function ( var ) { ggplot ( wine_data , aes_string ( x = var )) + geom_histogram ( fill = \"blue\" , color = \"black\" , bins = 30 ) + theme_minimal () + labs ( title = paste ( \"Distribui\u00e7\u00e3o de\" , var ), x = var , y = \"Frequ\u00eancia\" ) }) grid.arrange ( grobs = p , ncol = 3 )","title":"Distribui\u00e7\u00e3o de Vari\u00e1veis Num\u00e9ricas"},{"location":"datasourcing/#passo-6-analise-bivariada","text":"Examinaremos as rela\u00e7\u00f5es entre pares de vari\u00e1veis.","title":"Passo 6: An\u00e1lise Bivariada"},{"location":"datasourcing/#relacao-entre-alcool-e-qualidade","text":"# Scatter plot entre 'alcohol' e 'quality' ggplot ( wine_data , aes ( x = alcohol , y = quality )) + geom_point ( alpha = 0.5 ) + theme_minimal () + labs ( title = \"Rela\u00e7\u00e3o entre \u00c1lcool e Qualidade\" , x = \"\u00c1lcool\" , y = \"Qualidade\" )","title":"Rela\u00e7\u00e3o entre \u00c1lcool e Qualidade"},{"location":"datasourcing/#boxplot-da-qualidade-por-tipo-de-vinho","text":"# Supondo que h\u00e1 uma coluna 'type' indicando o tipo de vinho ggplot ( wine_data , aes ( x = factor ( quality ), y = alcohol , fill = factor ( quality ))) + geom_boxplot () + theme_minimal () + labs ( title = \"Boxplot da Qualidade por Tipo de Vinho\" , x = \"Qualidade\" , y = \"\u00c1lcool\" )","title":"Boxplot da Qualidade por Tipo de Vinho"},{"location":"datasourcing/#passo-7-analise-multivariada","text":"Analisaremos m\u00faltiplas vari\u00e1veis simultaneamente.","title":"Passo 7: An\u00e1lise Multivariada"},{"location":"datasourcing/#matriz-de-correlacao","text":"# Matriz de correla\u00e7\u00e3o cor_matrix <- cor ( wine_data %>% select_if ( is.numeric )) corrplot ( cor_matrix , method = \"circle\" )","title":"Matriz de Correla\u00e7\u00e3o"},{"location":"datasourcing/#scatterplot-matrix","text":"# Scatterplot matrix ggpairs ( wine_data %>% select_if ( is.numeric ))","title":"Scatterplot Matrix"},{"location":"datasourcing/#passo-8-conclusoes-e-insights","text":"Ap\u00f3s a an\u00e1lise, resumimos nossos principais achados: A distribui\u00e7\u00e3o da qualidade dos vinhos \u00e9... A rela\u00e7\u00e3o entre o teor de \u00e1lcool e a qualidade \u00e9... Vari\u00e1veis como \u00e1cido c\u00edtrico e pH apresentam correla\u00e7\u00e3o...","title":"Passo 8: Conclus\u00f5es e Insights"},{"location":"datasourcing/#referencias_1","text":"Documenta\u00e7\u00e3o do ggplot2 Guia de Introdu\u00e7\u00e3o ao dplyr","title":"Refer\u00eancias"},{"location":"datasourcing/#qual-a-missao-para-o-artefato","text":"Os grupos dever\u00e3o realizar uma An\u00e1lise Explorat\u00f3ria Avan\u00e7ada nos dados que foram fornecidos. Esta an\u00e1lise deve incluir, mas n\u00e3o se limitar a: Entender a estrutura dos dados e suas caracter\u00edsticas b\u00e1sicas. Realizar uma an\u00e1lise univariada de todas as vari\u00e1veis. Explorar rela\u00e7\u00f5es bivariadas entre vari\u00e1veis para identificar poss\u00edveis correla\u00e7\u00f5es. Conduzir uma an\u00e1lise multivariada para entender intera\u00e7\u00f5es complexas entre vari\u00e1veis. Utilizar visualiza\u00e7\u00f5es para ilustrar as descobertas e insights obtidos.","title":"Qual a Miss\u00e3o para o Artefato?"},{"location":"datasourcing/#uso-de-computacao-distribuida-com-spark","text":"Caso o conjunto de dados seja muito extenso e torne o processamento em um \u00fanico computador invi\u00e1vel, os grupos dever\u00e3o utilizar o Apache Spark como solu\u00e7\u00e3o de computa\u00e7\u00e3o distribu\u00edda. O Spark permite manipular e processar grandes volumes de dados de maneira eficiente, distribuindo as tarefas em m\u00faltiplos n\u00f3s de computa\u00e7\u00e3o. Utilizem essas ferramentas e t\u00e9cnicas para garantir que a an\u00e1lise seja completa e eficiente, mesmo com conjuntos de dados volumosos. O objetivo final \u00e9 extrair insights valiosos dos dados fornecidos e apresentar esses insights de forma clara e compreens\u00edvel.","title":"Uso de Computa\u00e7\u00e3o Distribu\u00edda com Spark"},{"location":"datastorytelling/","text":"","title":"Data Storytelling"},{"location":"etl/","text":"","title":"Servi\u00e7os e ETLs para Transforma\u00e7\u00e3o de Dados e Processamento de Dados em Escala (train at scale)"},{"location":"ingestao/","text":"","title":"Ingest\u00e3o e Processamento de Dados (Framework de testes e qualidade)"},{"location":"metricas/","text":"","title":"M\u00e9tricas, Telemetria e Gest\u00e3o de Microservi\u00e7os"},{"location":"mlops/","text":"","title":"Ciclo de Vida e Automatiza\u00e7\u00e3o de Pipeline de Dados (MLOps)"},{"location":"precificacao/","text":"","title":"Precifica\u00e7\u00e3o em Nuvem"},{"location":"predicao/","text":"","title":"Processamento e Predi\u00e7\u00e3o em Produ\u00e7\u00e3o"},{"location":"processamento/","text":"","title":"Processamento de Dados na Nuvem"},{"location":"seguranca/","text":"","title":"Seguran\u00e7a e Governan\u00e7a de Dados (LGPD)"},{"location":"ui_dashboards/","text":"","title":"User Interface e Dashboards"}]}